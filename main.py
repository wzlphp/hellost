from langchain_core.messages import AIMessageChunk, HumanMessage
import streamlit as st
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI
from langchain.tools import tool
import json
from loguru import logger
from langgraph.checkpoint.memory import InMemorySaver

 
 
# å®šä¹‰æ¨¡å‹
model = ChatOpenAI(
    model="deepseek/deepseek-v3.1-terminus",
    api_key="sk-fc27feb2aa6d3dac1131181fbde118073ed41863871113bf8b1ff24475483863",
    base_url="https://openai.qiniu.com/v1",
)

agent = create_agent(
    model=model,
    tools=[],
    system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ©æ‰‹ï¼Œä½ å¯ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚",
    checkpointer=InMemorySaver(),
)


# str = ''
# for data, matedata in agent.stream(
#     {"messages":HumanMessage(content="ä½ å¥½ï¼Œæˆ‘æ˜¯å¼ ä¸‰ã€‚ä½ æ˜¯è°ï¼Ÿ")},
#     stream_mode="messages"
# ):
#     # print(matedata)
#     str += data.content_blocks[0]['text']
#     print(str)
#     print("\n")

# exit()

st.set_page_config(page_title="æˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œæœ‰é—®é¢˜æ‰¾æˆ‘", page_icon="ğŸ¤–", layout="centered")
st.markdown("<h5 style='text-align: center;'>ğŸ¤– æˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œæœ‰é—®é¢˜æ‰¾æˆ‘</h5>", unsafe_allow_html=True)

# åˆå§‹åŒ– session_state
if "messages" not in st.session_state:
    st.session_state.messages = []


# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])


def token_get():
    for data, matedata in agent.stream(
        {"messages":HumanMessage(content=prompt)},
        stream_mode="messages",
        config={"configurable": {"thread_id": "123"}}
    ):
        if data.content_blocks:
            yield data.content_blocks[0]['text']

# å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥å†…å®¹..."):
    # 1. å…ˆæ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.chat_message("user").write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 2. è°ƒç”¨ä½ çš„å¤§æ¨¡å‹ï¼ˆè¿™é‡Œå…ˆç”¨æ¨¡æ‹Ÿå›å¤ç¤ºèŒƒï¼‰
    # reply = f"AIï¼šä½ åˆšæ‰è¯´çš„æ˜¯ï¼š{prompt}"
    # result = agent.invoke({"messages":HumanMessage(content=prompt)})
    # reply = result["messages"][-1].content

    
    msg = st.chat_message("assistant")
    container = msg.empty()
    # reply = ""
    # for data, matedata in agent.stream({"messages":HumanMessage(content=prompt)}, stream_mode="messages"):
    #     if data.content_blocks:
    #         reply += data.content_blocks[0]['text']
    #         logger.info(reply)
    #         container.write_stream(reply)

    reply = container.write_stream(token_get())

    st.success("å›ç­”å®Œæˆ!")
    # 3. æ˜¾ç¤º AI æ¶ˆæ¯å¹¶ä¿å­˜
    # st.chat_message("assistant").write(reply)
    st.session_state.messages.append({"role": "assistant", "content": reply})
